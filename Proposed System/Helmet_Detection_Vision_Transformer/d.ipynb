{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e09311-8eb5-464d-8d0b-5899f63d0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Configuration\n",
    "PRETRAINED_MODEL_NAME = \"google/vit-base-patch16-224-in21k\"\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 2e-5\n",
    "TRAIN_CSV_PATH = \"./train_labels.csv\"  # Path to training CSV\n",
    "TEST_CSV_PATH = \"./test_labels.csv\"  # Path to testing CSV\n",
    "BASE_DIR = \"./dataset/images\"  # Base directory for image paths\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 2: Initialize Model and Processor\n",
    "def initialize_model_and_processor(pretrained_model_name, num_labels, device):\n",
    "    model = ViTForImageClassification.from_pretrained(pretrained_model_name, num_labels=num_labels)\n",
    "    processor = ViTImageProcessor.from_pretrained(pretrained_model_name)\n",
    "    model = model.to(device)\n",
    "    return model, processor\n",
    "\n",
    "# Step 3: Define Dataset Class\n",
    "class HelmetDataset(Dataset):\n",
    "    def __init__(self, csv_file, processor, base_dir=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.processor = processor\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "        # Validate and correct paths\n",
    "        self.data['image_path'] = self.data['image_path'].apply(self.validate_path)\n",
    "        if self.data['image_path'].isnull().any():\n",
    "            raise ValueError(\"No valid image paths found in the CSV.\")\n",
    "\n",
    "    def validate_path(self, image_path):\n",
    "        if self.base_dir and not os.path.isabs(image_path):\n",
    "            image_path = os.path.join(self.base_dir, image_path)\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(f\"Invalid path: {image_path}\")\n",
    "            return None\n",
    "        return image_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        label = row['label']\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        return inputs[\"pixel_values\"].squeeze(0), torch.tensor(label)\n",
    "\n",
    "# Step 4: Create DataLoaders\n",
    "def create_dataloaders(train_csv, test_csv, processor, batch_size, base_dir):\n",
    "    train_dataset = HelmetDataset(train_csv, processor, base_dir)\n",
    "    test_dataset = HelmetDataset(test_csv, processor, base_dir)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Step 5: Training Function\n",
    "def train_model(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pixel_values, labels in tqdm(train_loader, desc=\"Training\", ncols=100):\n",
    "        pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Step 6: Evaluation Function\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pixel_values, labels in tqdm(test_loader, desc=\"Evaluating\", ncols=100):\n",
    "            pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(test_loader), accuracy\n",
    "\n",
    "# Step 7: Inference Function\n",
    "def predict(model, processor, image_path, device):\n",
    "    if not os.path.isfile(image_path):\n",
    "        raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=inputs['pixel_values'])\n",
    "        predicted_class = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    return predicted_class\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model and processor\n",
    "    model, processor = initialize_model_and_processor(PRETRAINED_MODEL_NAME, num_labels=2, device=DEVICE)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader, test_loader = create_dataloaders(TRAIN_CSV_PATH, TEST_CSV_PATH, processor, BATCH_SIZE, BASE_DIR)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training and Evaluation Loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "        train_loss = train_model(model, train_loader, optimizer, criterion, DEVICE)\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "        test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    output_dir = \"./helmet_detection_model\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.save_pretrained(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "    print(\"Model and processor saved successfully.\")\n",
    "\n",
    "    # Example inference\n",
    "    test_image_path = \"./dataset/test/images/sample.jpg\"  # Replace with a valid test image path\n",
    "    predicted_class = predict(model, processor, test_image_path, DEVICE)\n",
    "    print(f\"Predicted class for the test image: {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
