{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdea47a0-9314-4d63-b927-73e922d33aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from transformers import pipeline\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm  # For progress bars\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c28f24d-d0a8-45a7-95d6-fa180ee23878",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3874779078.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    helmet_detector = pipeline(\"image-classification\", model=\"./helmet_detection_model\", tokenizer=processor)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# 12. Inference with Pipeline (Optional - for future inference)\n",
    " helmet_detector = pipeline(\"image-classification\", model=\"./helmet_detection_model\", tokenizer=processor)\n",
    "# For inference on test images\n",
    "image_paths = [\"./test_image1.jpg\", \"./test_image2.jpg\", \"./test_image3.jpg\"]  # Replace with your test images\n",
    "\n",
    "results = []\n",
    "for img_path in tqdm(image_paths, desc=\"Processing Images\", ncols=100):\n",
    "    result = helmet_detector(img_path)\n",
    "    results.append((img_path, result))\n",
    "\n",
    "# Print inference results\n",
    "for img_path, result in results:\n",
    "    print(f\"Results for {img_path}: {result}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3604365-b55c-4e81-8864-84525c6361c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initialize_model_and_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Main Execution\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Initialize model and processor\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     model, processor \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model_and_processor\u001b[49m(PRETRAINED_MODEL_NAME, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Create DataLoaders\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     train_loader, test_loader \u001b[38;5;241m=\u001b[39m create_dataloaders(TRAIN_CSV_PATH, TEST_CSV_PATH, processor, BATCH_SIZE, BASE_DIR)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'initialize_model_and_processor' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 7: Inference Function\n",
    "def predict(model, processor, image_path, device):\n",
    "    if not os.path.isfile(image_path):\n",
    "        raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=inputs['pixel_values'])\n",
    "        predicted_class = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    return predicted_class\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model and processor\n",
    "    model, processor = initialize_model_and_processor(PRETRAINED_MODEL_NAME, num_labels=2, device=DEVICE)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader, test_loader = create_dataloaders(TRAIN_CSV_PATH, TEST_CSV_PATH, processor, BATCH_SIZE, BASE_DIR)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training and Evaluation Loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "        train_loss = train_model(model, train_loader, optimizer, criterion, DEVICE)\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "        test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    output_dir = \"./helmet_detection_model\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.save_pretrained(output_dir)\n",
    "    processor.save_pretrained(output_dir)\n",
    "    print(\"Model and processor saved successfully.\")\n",
    "\n",
    "    # Example inference\n",
    "    test_image_path = \"./dataset/test/images/sample.jpg\"  # Replace with a valid test image path\n",
    "    predicted_class = predict(model, processor, test_image_path, DEVICE)\n",
    "    print(f\"Predicted class for the test image: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9629a-6ed9-443c-a9f8-c3100f6f0bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
