{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1c2e1b-edea-4058-9ec2-df4208a91f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from transformers import pipeline\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm  # For progress bars\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0754da-3de7-4483-9b5f-441ce3e7e442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n",
      "Processing Images: 100%|██████████████████████████████████████████████| 3/3 [00:12<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ./Media/riders_1.jpg: [{'label': 'LABEL_1', 'score': 0.9951735138893127}, {'label': 'LABEL_0', 'score': 0.004826511722058058}]\n",
      "Results for ./Media/riders_2.jpg: [{'label': 'LABEL_1', 'score': 0.9950814247131348}, {'label': 'LABEL_0', 'score': 0.004918545950204134}]\n",
      "Results for ./Media/riders_3.jpg: [{'label': 'LABEL_1', 'score': 0.9950237274169922}, {'label': 'LABEL_0', 'score': 0.004976344760507345}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "# 12. Inference with Pipeline (Optional - for future inference)\n",
    "helmet_detector = pipeline(\"image-classification\", model=\"./models/helmet_vit\")\n",
    "# For inference on test images\n",
    "image_paths = [\"./Media/riders_1.jpg\", \"./Media/riders_2.jpg\", \"./Media/riders_3.jpg\"]  # Replace with your test images\n",
    "\n",
    "results = []\n",
    "for img_path in tqdm(image_paths, desc=\"Processing Images\", ncols=100):\n",
    "    result = helmet_detector(img_path)\n",
    "    results.append((img_path, result))\n",
    "\n",
    "# Print inference results\n",
    "for img_path, result in results:\n",
    "    print(f\"Results for {img_path}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db05e31-4cda-41f1-a140-33d9482e74d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
