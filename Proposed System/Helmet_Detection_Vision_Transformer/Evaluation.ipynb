{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1bc28f-9b91-4078-8bcf-addd799fe8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: Index(['image_path', 'label'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6684\\3463683922.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91       411\n",
      "           1       0.98      0.99      0.99      3135\n",
      "\n",
      "    accuracy                           0.98      3546\n",
      "   macro avg       0.97      0.93      0.95      3546\n",
      "weighted avg       0.98      0.98      0.98      3546\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m y_true_bin \u001b[38;5;241m=\u001b[39m label_binarize([label_to_idx[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m all_labels], classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(label_classes)))\n\u001b[0;32m    105\u001b[0m y_pred_bin \u001b[38;5;241m=\u001b[39m [label_to_idx[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m all_preds]\n\u001b[1;32m--> 106\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(\u001b[43my_true_bin\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, y_pred_bin)\n\u001b[0;32m    107\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n\u001b[0;32m    108\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(fpr, tpr, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForImageClassification, ViTImageProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Paths and configurations\n",
    "model_dir = \"./models/helmet_vit/\"\n",
    "train_csv = \"./train_labels.csv\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model and preprocessor\n",
    "model = AutoModelForImageClassification.from_pretrained(model_dir, local_files_only=True)\n",
    "processor = ViTImageProcessor.from_pretrained(model_dir)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(train_csv)\n",
    "print(\"Available columns:\", df.columns)\n",
    "\n",
    "# Extract image paths and labels\n",
    "image_paths = df['image_path'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "label_classes = sorted(set(labels))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(label_classes)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "# Define dataset class\n",
    "class HelmetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        from PIL import Image\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label_to_idx[label]\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset = HelmetDataset(image_paths, labels, transform)\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in dataloader:\n",
    "        images = images.to(device)\n",
    "        targets = torch.tensor(targets).to(device)\n",
    "        outputs = model(images).logits\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "# Convert predictions and labels back to class names\n",
    "all_preds = pd.Series(all_preds).map(idx_to_label).values\n",
    "all_labels = pd.Series(all_labels).map(idx_to_label).values\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Visualizations\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=label_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(label_classes)), label_classes, rotation=45)\n",
    "plt.yticks(range(len(label_classes)), label_classes)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "if len(label_classes) > 2:\n",
    "    y_true_bin = label_binarize([label_to_idx[label] for label in all_labels], classes=range(len(label_classes)))\n",
    "    y_pred_bin = label_binarize([label_to_idx[label] for label in all_preds], classes=range(len(label_classes)))\n",
    "    for i, class_name in enumerate(label_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"Class {class_name} (AUC = {roc_auc:.2f})\")\n",
    "else:\n",
    "    y_true_bin = label_binarize([label_to_idx[label] for label in all_labels], classes=range(len(label_classes)))\n",
    "    y_pred_bin = [label_to_idx[label] for label in all_preds]\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, 1], y_pred_bin)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_true_bin[:, 1], y_pred_bin)\n",
    "plt.plot(recall, precision, label=\"Precision-Recall Curve\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230769a6-f2c7-49ce-b467-979da09e1285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: Index(['image_path', 'label'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6684\\3153592316.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets).to(device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForImageClassification, ViTImageProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Paths and configurations\n",
    "model_dir = \"./models/helmet_vit/\"\n",
    "train_csv = \"./train_labels.csv\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model and preprocessor\n",
    "model = AutoModelForImageClassification.from_pretrained(model_dir, local_files_only=True)\n",
    "processor = ViTImageProcessor.from_pretrained(model_dir)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(train_csv)\n",
    "print(\"Available columns:\", df.columns)\n",
    "\n",
    "# Extract image paths and labels\n",
    "image_paths = df['image_path'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "label_classes = sorted(set(labels))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(label_classes)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "# Define dataset class\n",
    "class HelmetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        from PIL import Image\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label_to_idx[label]\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset = HelmetDataset(image_paths, labels, transform)\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in dataloader:\n",
    "        images = images.to(device)\n",
    "        targets = torch.tensor(targets).to(device)\n",
    "        outputs = model(images).logits\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "# Convert predictions and labels back to class names\n",
    "all_preds = pd.Series(all_preds).map(idx_to_label).values\n",
    "all_labels = pd.Series(all_labels).map(idx_to_label).values\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Visualizations\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=label_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(label_classes)), label_classes, rotation=45)\n",
    "plt.yticks(range(len(label_classes)), label_classes)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "if len(label_classes) > 2:\n",
    "    y_true_bin = label_binarize([label_to_idx[label] for label in all_labels], classes=range(len(label_classes)))\n",
    "    y_pred_bin = label_binarize([label_to_idx[label] for label in all_preds], classes=range(len(label_classes)))\n",
    "    for i, class_name in enumerate(label_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"Class {class_name} (AUC = {roc_auc:.2f})\")\n",
    "else:\n",
    "    # Binary classification: Use only the positive class (index 1)\n",
    "    y_true_bin = label_binarize([label_to_idx[label] for label in all_labels], classes=[0, 1])\n",
    "    y_pred_bin = label_binarize([label_to_idx[label] for label in all_preds], classes=[0, 1])\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, 1], y_pred_bin[:, 1])  # Index 1 for positive class\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_true_bin[:, 1], y_pred_bin[:, 1])  # Index 1 for positive class\n",
    "plt.plot(recall, precision, label=\"Precision-Recall Curve\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c193770-ddba-4aa9-879c-340f769436e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForImageClassification, ViTImageProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Paths and configurations\n",
    "model_dir = \"./models/helmet_vit/\"\n",
    "train_csv = \"./train_labels.csv\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model and preprocessor\n",
    "model = AutoModelForImageClassification.from_pretrained(model_dir, local_files_only=True)\n",
    "processor = ViTImageProcessor.from_pretrained(model_dir)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(train_csv)\n",
    "print(\"Available columns:\", df.columns)\n",
    "\n",
    "# Extract image paths and labels\n",
    "image_paths = df['image_path'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "label_classes = sorted(set(labels))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(label_classes)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "# Define dataset class\n",
    "class HelmetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        from PIL import Image\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label_to_idx[label]\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset = HelmetDataset(image_paths, labels, transform)\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in dataloader:\n",
    "        images = images.to(device)\n",
    "        targets = torch.tensor(targets).to(device)\n",
    "        outputs = model(images).logits\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "# Convert predictions and labels back to class names\n",
    "all_preds = pd.Series(all_preds).map(idx_to_label).values\n",
    "all_labels = pd.Series(all_labels).map(idx_to_label).values\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Visualizations\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=label_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(label_classes)), label_classes, rotation=45)\n",
    "plt.yticks(range(len(label_classes)), label_classes)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Prepare for ROC and Precision-Recall Curve\n",
    "y_true_bin = label_binarize([label_to_idx[label] for label in all_labels], classes=range(len(label_classes)))\n",
    "y_pred_bin = label_binarize([label_to_idx[label] for label in all_preds], classes=range(len(label_classes)))\n",
    "\n",
    "# ROC Curve\n",
    "if len(set(y_true_bin.flatten())) == 1 or len(set(y_pred_bin.flatten())) == 1:\n",
    "    print(\"Warning: Only one class present in the predictions or true labels. ROC curve cannot be computed.\")\n",
    "else:\n",
    "    if len(label_classes) > 2:\n",
    "        for i, class_name in enumerate(label_classes):\n",
    "            fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f\"Class {class_name} (AUC = {roc_auc:.2f})\")\n",
    "    else:\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, 1], y_pred_bin[:, 1])  # Index 1 for positive class\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_true_bin[:, 1], y_pred_bin[:, 1])  # Index 1 for positive class\n",
    "plt.plot(recall, precision, label=\"Precision-Recall Curve\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3b8c7-37db-4482-82e0-0340b4631f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForImageClassification, ViTImageProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Paths and configurations\n",
    "model_dir = \"./models/helmet_vit/\"\n",
    "train_csv = \"./train_labels.csv\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model and preprocessor\n",
    "model = AutoModelForImageClassification.from_pretrained(model_dir, local_files_only=True)\n",
    "processor = ViTImageProcessor.from_pretrained(model_dir)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(train_csv)\n",
    "print(\"Available columns:\", df.columns)\n",
    "\n",
    "# Extract image paths and labels\n",
    "image_paths = df['image_path'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "label_classes = sorted(set(labels))\n",
    "label_to_idx = {label: idx for idx, label in enumerate(label_classes)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "# Define dataset class\n",
    "class HelmetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        from PIL import Image\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label_to_idx[label]\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset = HelmetDataset(image_paths, labels, transform)\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in dataloader:\n",
    "        images = images.to(device)\n",
    "        targets = torch.tensor(targets).to(device)\n",
    "        outputs = model(images).logits\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "# Convert predictions and labels back to class names\n",
    "all_preds = pd.Series(all_preds).map(idx_to_label).values\n",
    "all_labels = pd.Series(all_labels).map(idx_to_label).values\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=label_classes, output_dict=True)\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Visualizations\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=label_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(label_classes)), label_classes, rotation=45)\n",
    "plt.yticks(range(len(label_classes)), label_classes)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# F1 Score, Precision, Recall visualization\n",
    "f1_scores = [report[cls]['f1-score'] for cls in label_classes]\n",
    "precisions = [report[cls]['precision'] for cls in label_classes]\n",
    "recalls = [report[cls]['recall'] for cls in label_classes]\n",
    "\n",
    "x = range(len(label_classes))\n",
    "\n",
    "# Plot F1 Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, f1_scores, color='skyblue')\n",
    "plt.xticks(x, label_classes, rotation=45)\n",
    "plt.title(\"F1 Scores for Each Class\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, precisions, color='lightgreen')\n",
    "plt.xticks(x, label_classes, rotation=45)\n",
    "plt.title(\"Precision for Each Class\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Recall\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, recalls, color='lightcoral')\n",
    "plt.xticks(x, label_classes, rotation=45)\n",
    "plt.title(\"Recall for Each Class\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac75a43-3985-49fd-89d6-881df6f183cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3511b80-b9b8-4ac1-8217-d9f24ae298ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
