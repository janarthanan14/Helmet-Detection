{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e29cc819-d873-4835-8c7d-7406318eb892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Processing Images: 100%|██████████████████████████████████████████████| 3/3 [00:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ./Media/riders_1.jpg: [{'label': 'LABEL_1', 'score': 0.9951735138893127}, {'label': 'LABEL_0', 'score': 0.004826511722058058}]\n",
      "Results for ./Media/riders_2.jpg: [{'label': 'LABEL_1', 'score': 0.9950814247131348}, {'label': 'LABEL_0', 'score': 0.004918545950204134}]\n",
      "Results for ./Media/riders_3.jpg: [{'label': 'LABEL_1', 'score': 0.9950237274169922}, {'label': 'LABEL_0', 'score': 0.004976344760507345}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Save the model and feature extractor\n",
    "#model.save_pretrained(\"./models/helmet_vit\")\n",
    "#feature_extractor.save_pretrained(\"./models/helmet_vit\")\n",
    "\n",
    "# Loading the model and feature extractor for inference\n",
    "helmet_detector = pipeline(\"image-classification\", model=\"./models/helmet_vit\")\n",
    "\n",
    "# If you are running inference over multiple images, here's how to show progress\n",
    "image_paths = [\"./Media/riders_1.jpg\", \"./Media/riders_2.jpg\", \"./Media/riders_3.jpg\"]  # List your test images\n",
    "\n",
    "# Show progress for inference\n",
    "results = []\n",
    "for img_path in tqdm(image_paths, desc=\"Processing Images\", ncols=100):\n",
    "    result = helmet_detector(img_path)\n",
    "    results.append((img_path, result))\n",
    "\n",
    "# Print the inference results\n",
    "for img_path, result in results:\n",
    "    print(f\"Results for {img_path}: {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee7eb65-aed6-4633-8d51-8ba562273c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load pre-trained model\n",
    "model_path = \"./models/helmet_vit\"\n",
    "helmet_detector = pipeline(\"image-classification\", model=model_path)\n",
    "\n",
    "# Create upload folder\n",
    "UPLOAD_FOLDER = \"./Media\"\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "app.config[\"UPLOAD_FOLDER\"] = UPLOAD_FOLDER\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
    "\n",
    "    file = request.files[\"file\"]\n",
    "    if file.filename == \"\":\n",
    "        return jsonify({\"error\": \"No file selected\"}), 400\n",
    "\n",
    "    # Save the uploaded image\n",
    "    file_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], file.filename)\n",
    "    file.save(file_path)\n",
    "\n",
    "    # Load and predict\n",
    "    image = Image.open(file_path).convert(\"RGB\")\n",
    "    result = helmet_detector(image)\n",
    "\n",
    "    # Delete the file after prediction\n",
    "    os.remove(file_path)\n",
    "\n",
    "    return jsonify({\"prediction\": result})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff26b65-1f4f-432e-b035-bd072ce8a36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from transformers import pipeline, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load pre-trained model\n",
    "model_path = \"./models/helmet_vit\"\n",
    "helmet_detector = pipeline(\n",
    "    \"image-classification\",\n",
    "    model=model_path,\n",
    "    feature_extractor=ViTImageProcessor.from_pretrained(model_path)\n",
    ")\n",
    "\n",
    "# Create upload folder\n",
    "UPLOAD_FOLDER = \"./Media\"\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "app.config[\"UPLOAD_FOLDER\"] = UPLOAD_FOLDER\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    if \"file\" not in request.files:\n",
    "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
    "\n",
    "    file = request.files[\"file\"]\n",
    "    if file.filename == \"\":\n",
    "        return jsonify({\"error\": \"No file selected\"}), 400\n",
    "\n",
    "    # Save the uploaded image\n",
    "    file_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], file.filename)\n",
    "    file.save(file_path)\n",
    "\n",
    "    try:\n",
    "        # Load and predict\n",
    "        image = Image.open(file_path).convert(\"RGB\")\n",
    "        result = helmet_detector(image)\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "    finally:\n",
    "        # Delete the file after prediction\n",
    "        os.remove(file_path)\n",
    "\n",
    "    return jsonify({\"prediction\": result})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae46c68-ae4e-4dcd-83a3-abdab9b0e65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
